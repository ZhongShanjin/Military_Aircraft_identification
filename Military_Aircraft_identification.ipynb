{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898fc8c6-0d90-4765-ad98-787465b1417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b197a654-ff13-476e-9f6b-115d7bb09799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting the path for joining multiple files\n",
    "crop_path = \"crop/\"\n",
    "files = os.path.join(crop_path, \"*/\")\n",
    "# list of merged files returned\n",
    "files = glob.glob(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c53a5275-d3c0-49b7-a4c7-c25d31868f62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p \"crop_data/train\"\n",
    "!mkdir -p \"crop_data/val\"\n",
    "for i in files:\n",
    "    categorie=i.split('/')[1]\n",
    "    print(categorie)\n",
    "    !mkdir -p \"crop_data/train/{categorie}\"\n",
    "    !mkdir -p \"crop_data/val/{categorie}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6c5c63c-2cf9-4ce1-9956-ba5f93b66b9e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "for dirname in files:\n",
    "    dirname = os.path.join(dirname, \"*\")\n",
    "    dirname = glob.glob(dirname)\n",
    "    train_data, val_data = train_test_split(dirname, test_size=0.1)\n",
    "    for i in train_data:\n",
    "#         print(\"crop_data/train/\"+i.split('/')[1])\n",
    "        if i not in \"crop_data/train/\"+i.split('/')[1]:\n",
    "            shutil.copy2(i[:-4] + \".jpg\", \"crop_data/train/\"+i.split('/')[1])\n",
    "    for i in val_data:             \n",
    "        if i not in \"crop_data/val/\"+i.split('/')[1]:\n",
    "            shutil.copy2(i[:-4] + \".jpg\", \"crop_data/val/\"+i.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35efbce3-0360-41cf-ae42-8ca46ec05b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从硬盘文件夹中加载图像数据集\n",
    "\n",
    "# 数据存储总路径\n",
    "data_dir = 'crop_data'\n",
    "# 图像的大小为224*256\n",
    "image_size = 256\n",
    "batch_sizes = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8769a44-11f5-4fcf-910a-97c62754d897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crop_data/train'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(data_dir, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "375a186b-6936-44e9-a833-0f879cf7d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从data_dir/train加载文件\n",
    "# 加载的过程将会对图像自动作如下的图像增强操作：\n",
    "# 1. 随机从原始图像中切下来一块224*224大小的区域\n",
    "# 2. 随机水平翻转图像\n",
    "# 3. 将图像的色彩数值标准化\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'),\n",
    "                                    transforms.Compose([\n",
    "                                        transforms.RandomResizedCrop(image_size),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e7690f2-9eaa-4a67-b65b-51caa1b7a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载校验数据集，对每个加载的数据进行如下处理：\n",
    "# 1. 放大到256*256像素\n",
    "# 2. 从中心区域切割下224*224大小的图像区域\n",
    "# 3. 将图像的色彩数值标准化\n",
    "val_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'),\n",
    "                                    transforms.Compose([\n",
    "                                        transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(image_size),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9737b9eb-627b-45a7-a4ff-e10aea6266cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 创建相应的数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_sizes, shuffle = True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_sizes, shuffle = True, num_workers=4)\n",
    "\n",
    "# 读取得出数据中的分类类别数\n",
    "num_classes = len(train_dataset.classes)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d48c7b2-781c-4a8e-aa19-a667bf179510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13352"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5da415b-2c84-4e5d-93db-9d2a25d34b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1503"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b312960c-89e0-4651-8ee9-732e8680b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测本机器是否安装GPU，将检测结果记录在布尔变量use_cuda中\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# 当可用GPU的时候，将新建立的张量自动加载到GPU中\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "itype = torch.cuda.LongTensor if use_cuda else torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b476a05-87ae-4ace-bad7-963887e8fac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def imshow(inp, title=None):\n",
    "#     # 将一张图打印显示出来，inp为一个张量，title为显示在图像上的文字\n",
    "    \n",
    "#     #一般的张量格式为：channels*image_width*image_height\n",
    "#     #而一般的图像为image_width*image_height*channels所以，需要将channels转换到最后一个维度\n",
    "#     inp = inp.numpy().transpose((1, 2, 0)) \n",
    "    \n",
    "#     #由于在读入图像的时候所有图像的色彩都标准化了，因此我们需要先调回去\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "#     inp = np.clip(inp, 0, 1)\n",
    "    \n",
    "#     #将图像绘制出来\n",
    "#     plt.imshow(inp)\n",
    "#     if title is not None:\n",
    "#         plt.title(title)\n",
    "#     plt.pause(0.001)  # 暂停一会是为了能够将图像显示出来。\n",
    "\n",
    "\n",
    "# #获取第一个图像batch和标签\n",
    "# images, labels = next(iter(train_loader))\n",
    "\n",
    "# # 将这个batch中的图像制成表格绘制出来\n",
    "# out = torchvision.utils.make_grid(images)\n",
    "\n",
    "# imshow(out, title=[train_dataset.classes[x] for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d26a248-cb52-47bd-8559-b7891e5c6e07",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d851a222434635905167f2e1efd26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型库中的residual network，并设置pretrained为true，这样便可加载相应的权重\n",
    "net = models.resnet50(pretrained=True)\n",
    "# 如果存在GPU，就将网络加载到GPU上\n",
    "net = net.cuda() if use_cuda else net\n",
    "# 将网络的架构打印出来\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff8e2d4a-0b25-4038-933d-b6c3e9b25017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class ConvNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConvNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, 3, padding = 1) #输入通道为3，输出通道为64，窗口大小为3，padding为1\n",
    "#         self.conv2 = nn.Conv2d(64, 64, 3, padding = 1) #第二层卷积，输入通道为64, 输出通道为64，窗口为3，padding为1\n",
    "#         self.pool = nn.MaxPool2d(2, 2) #一个窗口为2*2的pooling运算\n",
    "#         self.conv3 = nn.Conv2d(64, 64, 3, padding = 1) \n",
    "#         self.conv4 = nn.Conv2d(128, 128, 3, padding = 1) \n",
    "#         self.conv5 = nn.Conv2d(128, 256, 3, padding = 1) \n",
    "#         self.conv6 = nn.Conv2d(256, 256, 3, padding = 1)\n",
    "#         self.conv7 = nn.Conv2d(256, 512, 3, padding = 1)\n",
    "#         self.conv8 = nn.Conv2d(512, 512, 3, padding = 1)\n",
    "#         self.conv9 = nn.Conv2d(512, 512, 3, padding = 1)\n",
    "#         self.conv10 = nn.Conv2d(512, 512, 3, padding = 1)\n",
    "#         self.conv11 = nn.Conv2d(512, 512, 3, padding = 1)\n",
    "#         self.conv12 = nn.Conv2d(512, 512, 3, padding = 1)\n",
    "#         self.fc1 = nn.Linear(image_size // 32 * image_size // 32 * 512, 2048) #一个线性连接层，输入尺寸为最后一层立方体的平铺，输出层512个节点\n",
    "#         self.fc2 = nn.Linear(2048, 40) #最后一层线性分类单元，输入为\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         #神经网络完成一步前馈运算的过程，从输入到输出\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = torch.cat((F.relu6(x), F.relu6(-x)), 1)\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = self.pool(x)\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         x = torch.cat((F.relu6(x), F.relu6(-x)), 1)\n",
    "#         x = F.relu(self.conv4(x))\n",
    "#         x = self.pool(x)\n",
    "#         x = F.relu(self.conv5(x))\n",
    "#         x = F.relu(self.conv6(x))\n",
    "#         x = self.pool(x)\n",
    "#         x = F.relu(self.conv7(x))\n",
    "#         x = F.relu(self.conv8(x))\n",
    "#         x = F.relu(self.conv9(x))\n",
    "#         x = self.pool(x)\n",
    "#         x = F.relu(self.conv10(x))\n",
    "#         x = F.relu(self.conv11(x))\n",
    "#         x = F.relu(self.conv12(x))\n",
    "#         x = self.pool(x)\n",
    "#         x = x.view(-1, image_size // 32 * image_size // 32 * 512)\n",
    "#         x = F.dropout(x, training=self.training) #以默认为0.5的概率对这一层进行dropout操作\n",
    "#         x = F.relu(self.fc1(x)) #全链接，激活函数\n",
    "#         x = F.dropout(x, training=self.training) #以默认为0.5的概率对这一层进行dropout操作\n",
    "#         x = self.fc2(x) #全链接，激活函数\n",
    "#         x = F.log_softmax(x, dim=1) #log_softmax可以理解为概率对数值\n",
    "#         return x\n",
    "    \n",
    "#     def retrieve_features(self, x):\n",
    "#         #提取卷积神经网络的特征图的函数，返回feature_map1, feature_map2为前两层卷积层的特征图\n",
    "#         feature_map1 = F.relu(self.conv1(x))\n",
    "#         x = self.pool(feature_map1)\n",
    "#         feature_map2 = F.relu(self.conv2(x))\n",
    "#         return (feature_map1, feature_map2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f76e7846-dd8e-420a-a5b0-7be026a047a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rightness(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，batch_size行10列的矩阵，labels是数据之中的正确答案\"\"\"\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    # rights装到cpu中，以便后面打印出来   --hq20200726\n",
    "    rights = rights.cpu() if rights.is_cuda else rights\n",
    "    return rights, len(labels) #返回正确的数量和这一次一共比较了多少元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25531cb5-3974-40a0-a77f-7c61bddd2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取最后线性层的输入单元数，这是前面各层卷积提取到的特征数量\n",
    "num_ftrs = net.fc.in_features\n",
    "\n",
    "# 重新定义一个全新的线性层，它的输出为2，原本是1000\n",
    "net.fc = nn.Linear(num_ftrs, 40)\n",
    "\n",
    "#如果存在GPU则将网络加载到GPU中\n",
    "net.fc = net.fc.cuda() if use_cuda else net.fc\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #Loss函数的定义\n",
    "# 将网络的所有参数放入优化器中\n",
    "# optimizer = optim.SGD(net.parameters(), lr = 0.0001, momentum=0.9)\n",
    "torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "record = [] #记录准确率等数值的容器\n",
    "\n",
    "#开始训练循环\n",
    "num_epochs = 80\n",
    "net.train(True) # 给网络模型做标记，标志说模型在训练集上训练\n",
    "best_model = net\n",
    "best_r = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa353eb5-03ec-40f0-bfcb-433be943bbeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 加载网络\n",
    "# net = ConvNet()\n",
    "# # 如果有GPU就把网络加载到GPU中\n",
    "# net = net.cuda() if use_cuda else net\n",
    "# criterion = nn.CrossEntropyLoss() #Loss函数的定义\n",
    "# # optimizer = optim.SGD(net.parameters(), lr = 0.1, momentum=0.9)\n",
    "# optimizer=optim.Adam(net.parameters(),\n",
    "#                 lr=0.1,\n",
    "#                 betas=(0.9, 0.999),\n",
    "#                 eps=1e-08,\n",
    "#                 weight_decay=0.0005,\n",
    "#                 amsgrad=False)\n",
    "\n",
    "# record = [] #记录准确率等数值的容器\n",
    "\n",
    "# #开始训练循环\n",
    "# num_epochs = 20\n",
    "# net.train(True) # 给网络模型做标记，标志说模型在训练集上训练\n",
    "# best_model = net\n",
    "# best_r = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71c05c90-68c8-4180-a8b2-215152c53dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/apex-0.1-py3.8-linux-x86_64.egg/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)\n",
      "  warnings.warn(msg, DeprecatedFeatureWarning)\n"
     ]
    }
   ],
   "source": [
    "from apex import amp\n",
    "model, optimizer = amp.initialize(net, optimizer, opt_level=\"O1\") # 这里是“欧一”，不是“零一”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba9c67d3-0860-428d-ae1f-e670e6c05df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter: 23.59M\n"
     ]
    }
   ],
   "source": [
    "total = sum([param.nelement() for param in net.parameters()])\n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b48663c-d611-4ed5-8877-16461cf44b64",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "100 0\n",
      "训练周期: 0 \tLoss: 1.060304\t训练正确率: 69.47%, 校验正确率: 70.13%\n",
      "0 1\n",
      "100 1\n",
      "训练周期: 1 \tLoss: 1.034491\t训练正确率: 70.62%, 校验正确率: 71.26%\n",
      "0 2\n",
      "100 2\n",
      "训练周期: 2 \tLoss: 1.004780\t训练正确率: 71.68%, 校验正确率: 69.93%\n",
      "0 3\n",
      "100 3\n",
      "训练周期: 3 \tLoss: 1.003571\t训练正确率: 71.54%, 校验正确率: 70.19%\n",
      "0 4\n",
      "100 4\n",
      "训练周期: 4 \tLoss: 0.965135\t训练正确率: 72.30%, 校验正确率: 70.92%\n",
      "0 5\n",
      "100 5\n",
      "训练周期: 5 \tLoss: 0.954295\t训练正确率: 72.60%, 校验正确率: 71.99%\n",
      "0 6\n",
      "100 6\n",
      "训练周期: 6 \tLoss: 0.951282\t训练正确率: 72.96%, 校验正确率: 71.32%\n",
      "0 7\n",
      "100 7\n",
      "训练周期: 7 \tLoss: 0.927835\t训练正确率: 73.35%, 校验正确率: 73.45%\n",
      "0 8\n",
      "100 8\n",
      "训练周期: 8 \tLoss: 0.943730\t训练正确率: 73.20%, 校验正确率: 73.05%\n",
      "0 9\n",
      "100 9\n",
      "训练周期: 9 \tLoss: 0.904337\t训练正确率: 74.10%, 校验正确率: 71.12%\n",
      "0 10\n",
      "100 10\n",
      "训练周期: 10 \tLoss: 0.886320\t训练正确率: 74.45%, 校验正确率: 71.39%\n",
      "0 11\n",
      "100 11\n",
      "训练周期: 11 \tLoss: 0.893561\t训练正确率: 74.58%, 校验正确率: 71.06%\n",
      "0 12\n",
      "100 12\n",
      "训练周期: 12 \tLoss: 0.886128\t训练正确率: 74.54%, 校验正确率: 72.12%\n",
      "0 13\n",
      "100 13\n",
      "训练周期: 13 \tLoss: 0.875359\t训练正确率: 74.87%, 校验正确率: 71.79%\n",
      "0 14\n",
      "100 14\n",
      "训练周期: 14 \tLoss: 0.847779\t训练正确率: 75.27%, 校验正确率: 72.99%\n",
      "0 15\n",
      "100 15\n",
      "训练周期: 15 \tLoss: 0.857484\t训练正确率: 75.57%, 校验正确率: 74.32%\n",
      "0 16\n",
      "100 16\n",
      "训练周期: 16 \tLoss: 0.847256\t训练正确率: 75.17%, 校验正确率: 74.38%\n",
      "0 17\n",
      "100 17\n",
      "训练周期: 17 \tLoss: 0.821235\t训练正确率: 76.51%, 校验正确率: 73.12%\n",
      "0 18\n",
      "100 18\n",
      "训练周期: 18 \tLoss: 0.845582\t训练正确率: 75.85%, 校验正确率: 74.52%\n",
      "0 19\n",
      "100 19\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "训练周期: 19 \tLoss: 0.816530\t训练正确率: 76.55%, 校验正确率: 73.32%\n",
      "0 20\n",
      "100 20\n",
      "训练周期: 20 \tLoss: 0.765420\t训练正确率: 77.56%, 校验正确率: 74.38%\n",
      "0 21\n",
      "100 21\n",
      "训练周期: 21 \tLoss: 0.785214\t训练正确率: 77.31%, 校验正确率: 73.52%\n",
      "0 22\n",
      "100 22\n",
      "训练周期: 22 \tLoss: 0.772376\t训练正确率: 77.68%, 校验正确率: 74.18%\n",
      "0 23\n",
      "100 23\n",
      "训练周期: 23 \tLoss: 0.770612\t训练正确率: 77.65%, 校验正确率: 75.25%\n",
      "0 24\n",
      "100 24\n",
      "训练周期: 24 \tLoss: 0.758201\t训练正确率: 78.68%, 校验正确率: 75.85%\n",
      "0 25\n",
      "100 25\n",
      "训练周期: 25 \tLoss: 0.768201\t训练正确率: 77.90%, 校验正确率: 75.58%\n",
      "0 26\n",
      "100 26\n",
      "训练周期: 26 \tLoss: 0.758043\t训练正确率: 77.82%, 校验正确率: 76.05%\n",
      "0 27\n",
      "100 27\n",
      "训练周期: 27 \tLoss: 0.730626\t训练正确率: 78.72%, 校验正确率: 77.05%\n",
      "0 28\n",
      "100 28\n",
      "训练周期: 28 \tLoss: 0.740247\t训练正确率: 78.74%, 校验正确率: 74.45%\n",
      "0 29\n",
      "100 29\n",
      "训练周期: 29 \tLoss: 0.741488\t训练正确率: 78.51%, 校验正确率: 75.52%\n",
      "0 30\n",
      "100 30\n",
      "训练周期: 30 \tLoss: 0.712778\t训练正确率: 79.51%, 校验正确率: 76.05%\n",
      "0 31\n",
      "100 31\n",
      "训练周期: 31 \tLoss: 0.711014\t训练正确率: 79.67%, 校验正确率: 75.72%\n",
      "0 32\n",
      "100 32\n",
      "训练周期: 32 \tLoss: 0.714350\t训练正确率: 79.25%, 校验正确率: 75.05%\n",
      "0 33\n",
      "100 33\n",
      "训练周期: 33 \tLoss: 0.679414\t训练正确率: 80.37%, 校验正确率: 77.71%\n",
      "0 34\n",
      "100 34\n",
      "训练周期: 34 \tLoss: 0.701353\t训练正确率: 79.75%, 校验正确率: 75.85%\n",
      "0 35\n",
      "100 35\n",
      "训练周期: 35 \tLoss: 0.710620\t训练正确率: 79.46%, 校验正确率: 76.05%\n",
      "0 36\n",
      "100 36\n",
      "训练周期: 36 \tLoss: 0.674816\t训练正确率: 80.18%, 校验正确率: 76.58%\n",
      "0 37\n",
      "100 37\n",
      "训练周期: 37 \tLoss: 0.667948\t训练正确率: 80.61%, 校验正确率: 74.98%\n",
      "0 38\n",
      "100 38\n",
      "训练周期: 38 \tLoss: 0.684893\t训练正确率: 80.37%, 校验正确率: 75.18%\n",
      "0 39\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "100 39\n",
      "训练周期: 39 \tLoss: 0.660548\t训练正确率: 80.77%, 校验正确率: 77.38%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    #optimizer = exp_lr_scheduler(optimizer, epoch)\n",
    "    train_rights = [] #记录训练数据集准确率的容器\n",
    "    train_losses = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  #针对容器中的每一个批进行循环\n",
    "        if(batch_idx%100==0):\n",
    "            print(batch_idx,epoch)\n",
    "        data, target = data.clone().detach().requires_grad_(True), target.clone().detach() #data为图像，target为标签\n",
    "        #如果存在GPU则将变量加载到GPU中\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        output = net(data) #完成一次预测\n",
    "        loss = criterion(output, target) #计算误差\n",
    "        optimizer.zero_grad() #清空梯度\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "#         loss.backward() #反向传播\n",
    "        optimizer.step() #一步随机梯度下降\n",
    "        right = rightness(output, target) #计算准确率所需数值，返回正确的数值为（正确样例数，总样本数）\n",
    "        train_rights.append(right) #将计算结果装到列表容器中\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        train_losses.append(loss.data.numpy())\n",
    "\n",
    "    train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "\n",
    "    #在测试集上分批运行，并计算总的正确率\n",
    "    net.eval() #标志模型当前为运行阶段\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    vals = []\n",
    "    #对测试数据集进行循环\n",
    "    for data, target in val_loader:\n",
    "        #如果存在GPU则将变量加载到GPU中\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = data.clone().detach().requires_grad_(False), target.clone().detach()\n",
    "        output = net(data) #将特征数据喂入网络，得到分类的输出\n",
    "        val = rightness(output, target) #获得正确样本数以及总样本数\n",
    "        vals.append(val) #记录结果\n",
    "\n",
    "    #计算准确率\n",
    "    val_r = (sum([tup[0] for tup in vals]), sum([tup[1] for tup in vals]))\n",
    "    val_ratio = 1.0*val_r[0].numpy()/val_r[1]\n",
    "    \n",
    "    if val_ratio > best_r:\n",
    "        best_r = val_ratio\n",
    "        best_model = copy.deepcopy(net)\n",
    "    #打印准确率等数值，其中正确率为本训练周期Epoch开始后到目前撮的正确率的平均值\n",
    "    print('训练周期: {} \\tLoss: {:.6f}\\t训练正确率: {:.2f}%, 校验正确率: {:.2f}%'.format(\n",
    "        epoch, np.mean(train_losses), 100. * train_r[0].numpy() / train_r[1], 100. * val_r[0].numpy()/val_r[1]))       \n",
    "    record.append([np.mean(train_losses), train_r[0].numpy() / train_r[1], val_r[0].numpy()/val_r[1]])\n",
    "    torch.save(net,'checkp/model_res50')      # 将模型net另存为文件minst_conv_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e915483-40dd-44da-8e4c-5ab495dbb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model,'checkp/model_res50_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "295848fe-94b7-426b-8d65-f75e3140ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_best=torch.load('checkp/model_res50_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "851c5ff2-10fd-4f3f-a3c1-79d351501bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测验正确率: 77.58%\n"
     ]
    }
   ],
   "source": [
    "for data, target in val_loader:\n",
    "    #如果存在GPU则将变量加载到GPU中\n",
    "    if use_cuda:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    data, target = data.clone().detach().requires_grad_(False), target.clone().detach()\n",
    "    output = net_best(data) #将特征数据喂入网络，得到分类的输出\n",
    "    val = rightness(output, target) #获得正确样本数以及总样本数\n",
    "    vals.append(val) #记录结果\n",
    "#计算准确率\n",
    "val_r = (sum([tup[0] for tup in vals]), sum([tup[1] for tup in vals]))\n",
    "val_ratio = 1.0*val_r[0].numpy()/val_r[1]\n",
    "print('测验正确率: {:.2f}%'.format(val_ratio*100.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
